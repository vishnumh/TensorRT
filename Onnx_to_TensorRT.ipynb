{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX_to_TensorRT\n",
    "\n",
    "This part of the code requires an onnx parser to convert the onnx export to tensorrt engine. Please contact me if your interested further reagrding the onnx parser to run in jetson xavier. Kindly refer to this repo for https://github.com/arvcode/TensorRT_classifier_efficientNet for reference parser that was used for Jetson Nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "from onnx_helper import ONNXClassifierWrapper,convert_onnx_to_engine\n",
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpuid = 0\n",
    "device = torch.device('cpu') if gpuid < 0 else torch.device(f'cuda:{gpuid}')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For liftsplat shoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ONNX file.\n",
      "Building TensorRT engine. This may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "ONNX_PATH='models/simp_camenc_b0_1.onnx'\n",
    "TRT_PATH='models/simp_camenc_b0_1.trt'\n",
    "trt_engine=convert_onnx_to_engine(ONNX_PATH, TRT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ONNX file.\n",
      "Building TensorRT engine. This may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "ONNX_PATH='models/simp_camenc_b0.onnx'\n",
    "TRT_PATH='models/simp_camenc_b0.trt'\n",
    "trt_engine=convert_onnx_to_engine(ONNX_PATH, TRT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# logger to capture errors, warnings, and other information during the build and inference phases\n",
    "\n",
    "TRT_LOGGER = trt.Logger()\n",
    "ONNX_PATH='models/enpoints.onnx'\n",
    "ONNX_PATH='models/cam_encode_b1.onnx'\n",
    "#ONNX_PATH='models/efficientnetb2_batch1.onnx'\n",
    "TRT_PATH='models/enpoints.trt'\n",
    "\n",
    "def convert_onnx_to_engine(onnx_filename, engine_filename = None, max_batch_size = 32, max_workspace_size = 1 << 30, fp16_mode = True):\n",
    "    logger = trt.Logger(trt.Logger.WARNING)\n",
    "#https://github.com/onnx/onnx-tensorrt    \n",
    "    explicit_batch = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "    \n",
    "    with trt.Builder(logger) as builder, builder.create_network(explicit_batch) as network, trt.OnnxParser(network, logger) as parser:\n",
    "        builder.max_workspace_size = max_workspace_size\n",
    "        builder.fp16_mode = fp16_mode\n",
    "        builder.max_batch_size = max_batch_size\n",
    "\n",
    "        print(\"Parsing ONNX file.\")\n",
    "        with open(onnx_filename, 'rb') as model:\n",
    "            if not parser.parse(model.read()):\n",
    "                for error in range(parser.num_errors):\n",
    "                    print(parser.get_error(error))\n",
    "\n",
    "        last_layer = network.get_layer(network.num_layers - 1)\n",
    "        # Check if last layer recognizes it's output\n",
    "        if not last_layer.get_output(0):\n",
    "            # If not, then mark the output using TensorRT API\n",
    "            network.mark_output(last_layer.get_output(0))\n",
    "        print(\"Network Input shape\", network.num_inputs)\n",
    "        print(\"Network layers\", network.num_layers)\n",
    "        print(\"Network Output shape\",network.num_outputs)\n",
    "        print(\"Building TensorRT engine. This may take a few minutes.\")\n",
    "        engine = builder.build_cuda_engine(network)\n",
    "\n",
    "        if engine_filename:\n",
    "            with open(engine_filename, 'wb') as f:\n",
    "                f.write(engine.serialize())\n",
    "\n",
    "        return engine, logger\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
