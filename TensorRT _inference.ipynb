{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to TRT\n",
    "Reference :https://hemanths933.medium.com/convert-onnx-bert-model-to-tensorrt-e809276b01b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "from onnx_helper import ONNXClassifierWrapper,convert_onnx_to_engine\n",
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import onnxruntime as onnxrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpuid = 0\n",
    "device = torch.device('cpu') if gpuid < 0 else torch.device(f'cuda:{gpuid}')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lift Splat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set constants\n",
    "\n",
    "PRECISION=np.float32\n",
    "\n",
    "TRT_PATH='models/reduction_5_model.trt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TRT\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading TRT\")\n",
    "\n",
    "trt_model=ONNXClassifierWrapper('models/simp_cam_encode_b1.trt',[6, 64, 41, 8, 22],target_dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3, 128, 352)\n",
      "3244032\n"
     ]
    }
   ],
   "source": [
    "dummy_batch=torch.ones(6, 3, 128, 352).numpy()\n",
    "#dummy_batch=dummy_batch.transpose((0,3,2, 1))\n",
    "print(dummy_batch.shape)\n",
    "#dummy_batch = np.ascontiguousarray(dummy_batch)\n",
    "print(dummy_batch.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to eval in the model 24.132251739501953 ms \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "predictions1=trt_model.predict(dummy_batch)\n",
    "end = time.time()\n",
    "#print(\"Prediction\",predictions)\n",
    "print(f\"Time taken to eval in the model {(end-start)*1000} ms \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 44, 8, 22)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\n(shapes (6, 64, 41, 8, 22), (1, 64, 44, 8, 22) mismatch)\n x: array([[[[[ 4.537674e-04,  3.905300e-04, -3.677754e-05, ...,\n           -5.993718e-04,  9.560145e-04, -5.612092e-04],\n          [ 2.690700e-03,  2.336699e-03,  1.739836e-03, ...,...\n y: array([[[[[ 3.841190e-04,  3.894048e-04, -6.458013e-06, ...,\n           -4.762142e-04,  4.846490e-04, -7.814218e-04],\n          [ 2.690520e-03,  2.418729e-03,  1.786525e-03, ...,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e38eb63ca966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpred_onx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_onx4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_onx4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\n(shapes (6, 64, 41, 8, 22), (1, 64, 44, 8, 22) mismatch)\n x: array([[[[[ 4.537674e-04,  3.905300e-04, -3.677754e-05, ...,\n           -5.993718e-04,  9.560145e-04, -5.612092e-04],\n          [ 2.690700e-03,  2.336699e-03,  1.739836e-03, ...,...\n y: array([[[[[ 3.841190e-04,  3.894048e-04, -6.458013e-06, ...,\n           -4.762142e-04,  4.846490e-04, -7.814218e-04],\n          [ 2.690520e-03,  2.418729e-03,  1.786525e-03, ...,..."
     ]
    }
   ],
   "source": [
    "dummy_batch=torch.ones(1, 3, 128, 352, device =device)\n",
    "ort_session = onnxrt.InferenceSession('models/simp_cam_encode_b1.onnx', None, providers=[\"CUDAExecutionProvider\"])\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "inputs = [node for node in ort_session.get_inputs()][0]\n",
    "outputs = [node.name for node in ort_session.get_outputs()]\n",
    "\n",
    "pred_onx4 = ort_session.run(outputs, {inputs.name: to_numpy(dummy_batch)})\n",
    "print(pred_onx4[0].shape)\n",
    "np.testing.assert_allclose(predictions1, pred_onx4[0], rtol=1e-03, atol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274.0002"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(predictions1-pred_onx4[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building engine\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "def build_engine(model_file, max_ws=512*1024*1024, fp16=False):\n",
    "    print(\"building engine\")\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    builder.fp16_mode = fp16\n",
    "    config = builder.create_builder_config()\n",
    "    config.max_workspace_size = max_ws\n",
    "    if fp16:\n",
    "        config.flags |= 1 << int(trt.BuilderFlag.FP16)\n",
    "    \n",
    "    explicit_batch = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "    network = builder.create_network(explicit_batch)\n",
    "    with trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        with open(model_file, 'rb') as model:\n",
    "            parsed = parser.parse(model.read())\n",
    "            print(\"network.num_layers\", network.num_layers)\n",
    "            last_layer = network.get_layer(network.num_layers - 1)\n",
    "            network.mark_output(last_layer.get_output(0))\n",
    "            engine = builder.build_engine(network, config=config)\n",
    "            return engine\n",
    "engine = build_engine(\"models/camencode_b0.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/camencode_b0.trt', 'wb') as f:\n",
    "    f.write(bytearray(engine.serialize()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
